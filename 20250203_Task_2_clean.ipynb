{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 50/50 [09:08<00:00, 10.98s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, cohen_kappa_score\n",
    "import yasa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm  # Progress bar\n",
    "import warnings  # Suppress warnings\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import sys\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "import io\n",
    "\n",
    "# -------------------------------\n",
    "# Configuration and Setup\n",
    "# -------------------------------\n",
    "CURRENT_DATE = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "CURRENT_USER = \"ZiadATAhmed\"\n",
    "DATASET_DIR = \"dataset/\"\n",
    "\n",
    "# Create logs directory if it doesn't exist\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "log_filename = os.path.join('logs', f'sleep_analysis_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(levelname)s | %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler(sys.stdout)\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set publication-ready matplotlib settings\n",
    "plt.rcParams.update({\n",
    "    \"font.size\": 14,\n",
    "    \"figure.figsize\": (18, 10),\n",
    "    \"axes.titlesize\": 16,\n",
    "    \"axes.labelsize\": 16,\n",
    "    \"xtick.labelsize\": 14,\n",
    "    \"ytick.labelsize\": 14,\n",
    "    \"legend.fontsize\": 14,\n",
    "    \"figure.titlesize\": 18,\n",
    "    \"lines.linewidth\": 2\n",
    "})\n",
    "\n",
    "# For five-class sleep staging, we use these stage names.\n",
    "STAGE_NAMES = [\"WAKE\", \"N1\", \"N2\", \"N3\", \"REM\"]\n",
    "# The five-class mapping corresponds to integer labels [0, 1, 2, 3, 4].\n",
    "\n",
    "# -------------------------------\n",
    "# Utility Functions\n",
    "# -------------------------------\n",
    "def suppress_output(func):\n",
    "    \"\"\"Decorator to suppress stdout and stderr output.\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        with redirect_stdout(io.StringIO()), redirect_stderr(io.StringIO()):\n",
    "            return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "def parse_nsrr_xml(xml_file):\n",
    "    \"\"\"\n",
    "    Parses an NSRR XML file (expected to end with \"-nsrr.xml\") to extract sleep stage annotations.\n",
    "    Assumes each \"ScoredEvent\" with EventType \"Stages|Stages\" contains:\n",
    "      - EventConcept: where the last element after splitting by \"|\" is the stage (numeric)\n",
    "      - Duration: duration in seconds (must be a multiple of 30)\n",
    "    Returns:\n",
    "      A numpy array of raw sleep stage values repeated for each 30-second epoch.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error parsing XML file {xml_file}: {e}\")\n",
    "\n",
    "    hypnogram = []\n",
    "    for event in root.findall(\".//ScoredEvent\"):\n",
    "        event_type = event.find(\"EventType\")\n",
    "        if event_type is None or event_type.text != \"Stages|Stages\":\n",
    "            continue\n",
    "        duration_elem = event.find(\"Duration\")\n",
    "        concept_elem = event.find(\"EventConcept\")\n",
    "        if duration_elem is None or concept_elem is None:\n",
    "            continue\n",
    "        stage_str = concept_elem.text.split(\"|\")[-1]\n",
    "        hypnogram.append((stage_str, duration_elem.text))\n",
    "    \n",
    "    stages = []\n",
    "    for stage_str, duration_str in hypnogram:\n",
    "        try:\n",
    "            stage = int(stage_str)\n",
    "        except ValueError:\n",
    "            continue  # Skip non-numeric annotations\n",
    "        duration = float(duration_str)\n",
    "        if duration % 30 != 0:\n",
    "            raise ValueError(\"Annotation duration is not a multiple of 30 seconds.\")\n",
    "        epochs_duration = int(duration) // 30\n",
    "        stages.extend([stage] * epochs_duration)\n",
    "    \n",
    "    if not stages:\n",
    "        raise ValueError(\"No valid sleep stage annotations were found in the XML file.\")\n",
    "    \n",
    "    return np.array(stages)\n",
    "\n",
    "def map_stage(stage):\n",
    "    \"\"\"\n",
    "    Maps the raw stage integer from the XML to a sleep stage label for five classes.\n",
    "    Mapping:\n",
    "      - 0 -> WAKE\n",
    "      - 1 -> N1\n",
    "      - 2 -> N2\n",
    "      - 3 or 4 -> N3   (N3 and N4 merged)\n",
    "      - 5 -> REM\n",
    "    Any other stage is mapped to \"UNS\".\n",
    "    \"\"\"\n",
    "    if stage == 0:\n",
    "        return \"WAKE\"\n",
    "    elif stage == 1:\n",
    "        return \"N1\"\n",
    "    elif stage == 2:\n",
    "        return \"N2\"\n",
    "    elif stage in (3, 4):\n",
    "        return \"N3\"\n",
    "    elif stage == 5:\n",
    "        return \"REM\"\n",
    "    else:\n",
    "        return \"UNS\"\n",
    "\n",
    "# -------------------------------\n",
    "# Core Analysis Class\n",
    "# -------------------------------\n",
    "class SleepAnalysis:\n",
    "    def __init__(self, dataset_dir):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.metrics_dict = {}\n",
    "        self.overall_true = []\n",
    "        self.overall_pred = []\n",
    "        logger.info(f\"Analysis initialized by {CURRENT_USER} at {CURRENT_DATE}\")\n",
    "\n",
    "    @suppress_output\n",
    "    def preprocess_eeg(self, raw):\n",
    "        \"\"\"Resample and filter the EEG data.\"\"\"\n",
    "        raw.resample(100, npad=\"auto\")\n",
    "        raw.filter(0.3, 45, fir_design=\"firwin\", verbose=False)\n",
    "        return raw\n",
    "\n",
    "    def evaluate_sleep_staging(self, edf_file, xml_file):\n",
    "        \"\"\"\n",
    "        Evaluates sleep staging on one EDF file paired with its NSRR XML annotation.\n",
    "        Steps:\n",
    "          1. Read and preprocess the EDF file.\n",
    "          2. Parse XML to extract true sleep stage annotations.\n",
    "          3. Map raw annotations to stage labels using `map_stage`.\n",
    "          4. Convert these to integer labels via YASA's Hypnogram.\n",
    "          5. Perform automatic sleep staging using YASA.\n",
    "          6. Compute evaluation metrics.\n",
    "        Returns a dictionary with accuracy, confusion matrix, classification report,\n",
    "        Cohen's kappa, true labels, predicted labels, and raw EEG.\n",
    "        \"\"\"\n",
    "        logger.info(f\"Processing EDF file: {edf_file}\")\n",
    "        try:\n",
    "            raw = mne.io.read_raw_edf(edf_file, preload=True, verbose=False)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to read EDF file {edf_file}: {e}\")\n",
    "            raise\n",
    "\n",
    "        raw = self.preprocess_eeg(raw)\n",
    "\n",
    "        # Parse XML and map annotations\n",
    "        try:\n",
    "            hypnogram = parse_nsrr_xml(xml_file)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing XML {xml_file}: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Map raw stages to five-class labels\n",
    "        hypno_labels = [map_stage(stage) for stage in hypnogram]\n",
    "        # Convert string labels to integer labels using YASA's Hypnogram.\n",
    "        # YASA will map: \"WAKE\"->0, \"N1\"->1, \"N2\"->2, \"N3\"->3, \"REM\"->4.\n",
    "        try:\n",
    "            true_hyp = yasa.Hypnogram(hypno_labels, freq=\"30s\")\n",
    "            true_int = true_hyp.as_int()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error converting hypnogram to integer labels: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Automatic sleep staging using YASA\n",
    "        try:\n",
    "            sls = yasa.SleepStaging(raw, eeg_name=\"EEG\", eog_name=\"EOG(L)\", emg_name=\"EMG\")\n",
    "            hypno_pred = sls.predict()\n",
    "            pred_int = yasa.hypno_str_to_int(hypno_pred)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during sleep staging prediction: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Ensure both arrays have the same length.\n",
    "        if len(true_int) != len(pred_int):\n",
    "            err_msg = \"Mismatch in the number of epochs between true annotations and predictions.\"\n",
    "            logger.error(err_msg)\n",
    "            raise ValueError(err_msg)\n",
    "\n",
    "        # Use consistent label order [0, 1, 2, 3, 4] for confusion matrix and reporting.\n",
    "        accuracy = 100 * accuracy_score(true_int, pred_int)\n",
    "        cm = confusion_matrix(true_int, pred_int, labels=[0, 1, 2, 3, 4])\n",
    "        class_report = classification_report(true_int, pred_int, target_names=STAGE_NAMES)\n",
    "        kappa = cohen_kappa_score(true_int, pred_int)\n",
    "\n",
    "        logger.info(f\"File processed. Accuracy: {accuracy:.2f}%, Cohen's Kappa: {kappa:.2f}\")\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"confusion_matrix\": cm,\n",
    "            \"classification_report\": class_report,\n",
    "            \"cohen_kappa\": kappa,\n",
    "            \"true_int\": true_int,\n",
    "            \"pred_int\": pred_int,\n",
    "            \"raw\": raw\n",
    "        }\n",
    "        return metrics\n",
    "\n",
    "    def process_dataset(self):\n",
    "        \"\"\"\n",
    "        Processes all EDF/NSRR XML pairs in the dataset directory.\n",
    "        Aggregates per-sample metrics and accumulates overall true and predicted labels.\n",
    "        \"\"\"\n",
    "        edf_files = glob.glob(os.path.join(self.dataset_dir, \"**\", \"*.edf\"), recursive=True)\n",
    "        if not edf_files:\n",
    "            logger.error(\"No EDF files found in the dataset directory.\")\n",
    "            return\n",
    "\n",
    "        for edf_file in tqdm(edf_files, desc=\"Processing files\"):\n",
    "            base = os.path.splitext(edf_file)[0]\n",
    "            xml_file = base + \"-nsrr.xml\"\n",
    "            sample_name = os.path.basename(base)\n",
    "            if not os.path.exists(xml_file):\n",
    "                logger.warning(f\"XML file not found for {edf_file}. Skipping.\")\n",
    "                continue\n",
    "            try:\n",
    "                metrics = self.evaluate_sleep_staging(edf_file, xml_file)\n",
    "                self.metrics_dict[sample_name] = metrics\n",
    "                self.overall_true.extend(metrics[\"true_int\"])\n",
    "                self.overall_pred.extend(metrics[\"pred_int\"])\n",
    "                logger.info(f\"Successfully processed sample: {sample_name}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {edf_file}: {e}\")\n",
    "                continue\n",
    "\n",
    "    def plot_results(self):\n",
    "        \"\"\"\n",
    "        Generates plots including:\n",
    "          - A grouped bar chart of per-sample accuracy and Cohen's kappa.\n",
    "          - An aggregated confusion matrix heatmap.\n",
    "          - A text panel for the overall classification report.\n",
    "          - Individual hypnogram comparisons.\n",
    "        Saves plots to an output directory.\n",
    "        \"\"\"\n",
    "        if not self.metrics_dict:\n",
    "            logger.error(\"No metrics available for plotting.\")\n",
    "            return\n",
    "\n",
    "        output_dir = f\"results_{datetime.now().strftime('%Y%m%d')}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        sample_names = list(self.metrics_dict.keys())\n",
    "        x_values = np.arange(1, len(sample_names) + 1)\n",
    "        accuracies = [self.metrics_dict[s][\"accuracy\"] for s in sample_names]\n",
    "        kappas = [self.metrics_dict[s][\"cohen_kappa\"] * 100 for s in sample_names]\n",
    "\n",
    "        # Aggregate confusion matrix across samples using consistent labels [0,1,2,3,4]\n",
    "        agg_cm = None\n",
    "        for s in sample_names:\n",
    "            if agg_cm is None:\n",
    "                agg_cm = self.metrics_dict[s][\"confusion_matrix\"]\n",
    "            else:\n",
    "                agg_cm += self.metrics_dict[s][\"confusion_matrix\"]\n",
    "\n",
    "        overall_class_report = classification_report(self.overall_true, self.overall_pred, target_names=STAGE_NAMES)\n",
    "\n",
    "        # Create combined figure with three panels\n",
    "        fig = plt.figure(constrained_layout=True, figsize=(18, 12))\n",
    "        gs = fig.add_gridspec(2, 2)\n",
    "\n",
    "        # Panel 1: Grouped Bar Chart (per-sample metrics)\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        width = 0.25\n",
    "        ax1.bar(x_values - width/2, accuracies, width, label='Accuracy')\n",
    "        ax1.bar(x_values + width/2, kappas, width, label=\"Cohen's Kappa\")\n",
    "        ax1.set_ylabel(\"Percentage\", fontsize=14)\n",
    "        ax1.set_title(\"Per-Sample Metrics\", fontsize=16)\n",
    "        ax1.set_xticks(x_values)\n",
    "        ax1.set_xticklabels([s[-4:] for s in sample_names], rotation=45, ha='center', fontsize=10)\n",
    "        ax1.legend(fontsize=12, loc='upper center', bbox_to_anchor=(0.5, -0.10), ncol=2)\n",
    "        ax1.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "        # Panel 2: Aggregated Confusion Matrix Heatmap\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        sns.heatmap(agg_cm, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "                    xticklabels=STAGE_NAMES, yticklabels=STAGE_NAMES, ax=ax2)\n",
    "        ax2.set_title(\"Aggregated Confusion Matrix\", fontsize=16)\n",
    "        ax2.set_xlabel(\"Predicted Stage\", fontsize=14)\n",
    "        ax2.set_ylabel(\"True Stage\", fontsize=14)\n",
    "\n",
    "        # Panel 3: Overall Classification Report (text)\n",
    "        ax3 = fig.add_subplot(gs[1, :])\n",
    "        ax3.axis(\"off\")\n",
    "        ax3.set_title(\"Overall Classification Report\", fontsize=16, pad=30, loc='left')\n",
    "        ax3.text(0, 0.5, overall_class_report, fontsize=14, family=\"monospace\")\n",
    "        plt.suptitle(\"Sleep Staging Evaluation Summary\", fontsize=20)\n",
    "        combined_fig_path = os.path.join(output_dir, \"combined_analysis.png\")\n",
    "        plt.savefig(combined_fig_path, bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "        logger.info(f\"Combined analysis figure saved to {combined_fig_path}\")\n",
    "\n",
    "        # Save individual hypnogram comparisons\n",
    "        for sample_name, metrics in self.metrics_dict.items():\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            time_axis = np.arange(len(metrics[\"true_int\"])) * 30 / 3600  # Convert epochs to hours\n",
    "            plt.plot(time_axis, metrics[\"true_int\"], label=\"True\", alpha=0.7)\n",
    "            plt.plot(time_axis, metrics[\"pred_int\"], label=\"Predicted\", alpha=0.7, linestyle=\"--\")\n",
    "            plt.title(f\"Hypnogram Comparison - {sample_name}\")\n",
    "            plt.xlabel(\"Time (hours)\")\n",
    "            plt.ylabel(\"Sleep Stage\")\n",
    "            plt.yticks(ticks=[0, 1, 2, 3, 4], labels=STAGE_NAMES)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            hypnogram_path = os.path.join(output_dir, f\"hypnogram_{sample_name}.png\")\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(hypnogram_path, dpi=300)\n",
    "            plt.close()\n",
    "            logger.info(f\"Hypnogram for sample {sample_name} saved to {hypnogram_path}\")\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"\n",
    "        Generates a text report summarizing overall and per-sample metrics.\n",
    "        \"\"\"\n",
    "        report_path = f\"sleep_analysis_report_{datetime.now().strftime('%Y%m%d')}.txt\"\n",
    "        overall_acc = accuracy_score(self.overall_true, self.overall_pred) * 100\n",
    "        overall_kappa = cohen_kappa_score(self.overall_true, self.overall_pred)\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(\"Sleep Analysis Report\\n\")\n",
    "            f.write(f\"Generated by: {CURRENT_USER}\\n\")\n",
    "            f.write(f\"Date: {CURRENT_DATE}\\n\")\n",
    "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            f.write(\"Overall Metrics:\\n\")\n",
    "            f.write(f\"Accuracy: {overall_acc:.2f}%\\n\")\n",
    "            f.write(f\"Cohen's Kappa: {overall_kappa:.2f}\\n\\n\")\n",
    "            f.write(\"Per-sample Metrics:\\n\")\n",
    "            for sample_name, metrics in self.metrics_dict.items():\n",
    "                f.write(f\"\\nSample: {sample_name}\\n\")\n",
    "                f.write(f\"Accuracy: {metrics['accuracy']:.2f}%\\n\")\n",
    "                f.write(f\"Cohen's Kappa: {metrics['cohen_kappa']:.2f}\\n\")\n",
    "                f.write(\"Classification Report:\\n\")\n",
    "                f.write(metrics[\"classification_report\"])\n",
    "                f.write(\"\\n\" + \"-\" * 50 + \"\\n\")\n",
    "        logger.info(f\"Report generated: {report_path}\")\n",
    "\n",
    "# -------------------------------\n",
    "# Main Execution\n",
    "# -------------------------------\n",
    "def main():\n",
    "    try:\n",
    "        analysis = SleepAnalysis(DATASET_DIR)\n",
    "        logger.info(\"Starting dataset processing\")\n",
    "        analysis.process_dataset()\n",
    "        logger.info(\"Dataset processing completed\")\n",
    "        logger.info(\"Generating plots and report\")\n",
    "        analysis.plot_results()\n",
    "        analysis.generate_report()\n",
    "        logger.info(\"Analysis completed successfully\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Analysis failed: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
