{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 50/50 [09:03<00:00, 10.86s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import mne\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, cohen_kappa_score\n",
    "import yasa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import sys\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "import io\n",
    "\n",
    "# Configuration and Setup\n",
    "CURRENT_DATE = \"2025-02-03 12:01:57\"\n",
    "CURRENT_USER = \"ZiadATAhmed\"\n",
    "\n",
    "# Create logs directory if it doesn't exist\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "\n",
    "# Set up logging\n",
    "log_filename = os.path.join('logs', f'sleep_analysis_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s | %(levelname)s | %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filename),\n",
    "        logging.StreamHandler(open(os.devnull, 'w'))  # Redirect stdout to null\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define stage names and labels for all possible stages\n",
    "STAGE_NAMES = [\"WAKE\", \"N1\", \"N2\", \"N3\", \"REM\", \"UNKNOWN\"]\n",
    "STAGE_LABELS = [0, 1, 2, 3, 5, 6]  # Include all possible stage values\n",
    "\n",
    "def suppress_output(func):\n",
    "    \"\"\"Decorator to suppress stdout and stderr output\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        with redirect_stdout(io.StringIO()), redirect_stderr(io.StringIO()):\n",
    "            result = func(*args, **kwargs)\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "class SleepAnalysis:\n",
    "    def __init__(self, dataset_dir):\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.metrics_dict = {}\n",
    "        self.overall_true = []\n",
    "        self.overall_pred = []\n",
    "        logger.info(f\"Analysis initialized by {CURRENT_USER} at {CURRENT_DATE}\")\n",
    "\n",
    "    def parse_nsrr_xml(self, xml_file):\n",
    "        \"\"\"Parse NSRR XML file for sleep stage annotations.\"\"\"\n",
    "        try:\n",
    "            tree = ET.parse(xml_file)\n",
    "            root = tree.getroot()\n",
    "            \n",
    "            stages = []\n",
    "            for event in root.findall(\".//ScoredEvent\"):\n",
    "                if event.find(\"EventType\").text == \"Stages|Stages\":\n",
    "                    stage = int(event.find(\"EventConcept\").text.split(\"|\")[-1])\n",
    "                    duration = float(event.find(\"Duration\").text)\n",
    "                    epochs = int(duration // 30)\n",
    "                    stages.extend([stage] * epochs)\n",
    "                    \n",
    "            return np.array(stages)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error parsing XML file {xml_file}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @suppress_output\n",
    "    def preprocess_eeg(self, raw):\n",
    "        \"\"\"Preprocess EEG data.\"\"\"\n",
    "        raw.resample(100, verbose=False)\n",
    "        raw.filter(0.3, 45, verbose=False)\n",
    "        return raw\n",
    "\n",
    "    def detect_artifacts(self, raw, threshold=100e-6):\n",
    "        \"\"\"Detect artifacts in EEG data.\"\"\"\n",
    "        data = raw.get_data()\n",
    "        artifacts = np.abs(data) > threshold\n",
    "        artifact_percentage = np.mean(artifacts) * 100\n",
    "        logger.info(f\"Artifact percentage: {artifact_percentage:.2f}%\")\n",
    "        return artifacts\n",
    "\n",
    "    @suppress_output\n",
    "    def evaluate_sleep_staging(self, edf_file, xml_file):\n",
    "        \"\"\"Evaluate sleep staging for a single recording.\"\"\"\n",
    "        try:\n",
    "            # Load and preprocess EEG\n",
    "            raw = mne.io.read_raw_edf(edf_file, preload=True, verbose=False)\n",
    "            raw = self.preprocess_eeg(raw)\n",
    "\n",
    "            # Get true stages\n",
    "            true_stages = self.parse_nsrr_xml(xml_file)\n",
    "            \n",
    "            # Perform automatic sleep staging\n",
    "            sls = yasa.SleepStaging(raw, eeg_name=\"EEG\", eog_name=\"EOG(L)\", emg_name=\"EMG\")\n",
    "            pred_stages = sls.predict()\n",
    "            pred_int = yasa.hypno_str_to_int(pred_stages)\n",
    "\n",
    "            # Calculate metrics using all possible labels\n",
    "            metrics = {\n",
    "                \"accuracy\": accuracy_score(true_stages, pred_int) * 100,\n",
    "                \"confusion_matrix\": confusion_matrix(true_stages, pred_int, \n",
    "                                                  labels=STAGE_LABELS),\n",
    "                \"classification_report\": classification_report(true_stages, pred_int, \n",
    "                                                          labels=STAGE_LABELS,\n",
    "                                                          target_names=STAGE_NAMES,\n",
    "                                                          zero_division=0),\n",
    "                \"cohen_kappa\": cohen_kappa_score(true_stages, pred_int),\n",
    "                \"true_stages\": true_stages,\n",
    "                \"pred_stages\": pred_int,\n",
    "                \"raw\": raw\n",
    "            }\n",
    "            \n",
    "            return metrics\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {edf_file}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def process_dataset(self):\n",
    "        \"\"\"Process all files in the dataset.\"\"\"\n",
    "        edf_files = glob.glob(os.path.join(self.dataset_dir, \"*.edf\"))\n",
    "        \n",
    "        for edf_file in tqdm(edf_files, desc=\"Processing files\", file=sys.stdout):\n",
    "            try:\n",
    "                xml_file = edf_file.replace(\".edf\", \"-nsrr.xml\")\n",
    "                if not os.path.exists(xml_file):\n",
    "                    logger.warning(f\"No XML file found for {edf_file}\")\n",
    "                    continue\n",
    "                    \n",
    "                metrics = self.evaluate_sleep_staging(edf_file, xml_file)\n",
    "                sample_name = os.path.basename(edf_file).replace(\".edf\", \"\")\n",
    "                self.metrics_dict[sample_name] = metrics\n",
    "                \n",
    "                self.overall_true.extend(metrics[\"true_stages\"])\n",
    "                self.overall_pred.extend(metrics[\"pred_stages\"])\n",
    "                \n",
    "                logger.info(f\"Successfully processed {sample_name}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {edf_file}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "    def plot_results(self):\n",
    "        \"\"\"Generate and save all plots.\"\"\"\n",
    "        if not self.metrics_dict:\n",
    "            logger.error(\"No data available for plotting\")\n",
    "            return\n",
    "\n",
    "        # Create output directory for plots\n",
    "        output_dir = f\"results_{CURRENT_DATE.split()[0]}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Create a single figure with three panels\n",
    "        fig = plt.figure(figsize=(20, 15))\n",
    "        gs = fig.add_gridspec(2, 2)\n",
    "\n",
    "        # Panel 1: Performance Metrics Bar Chart\n",
    "        ax1 = fig.add_subplot(gs[0, 0])\n",
    "        sample_names = list(self.metrics_dict.keys())\n",
    "        x_values = np.arange(len(sample_names))\n",
    "        accuracies = [m[\"accuracy\"] for m in self.metrics_dict.values()]\n",
    "        kappas = [m[\"cohen_kappa\"] * 100 for m in self.metrics_dict.values()]\n",
    "        \n",
    "        width = 0.35\n",
    "        ax1.bar(x_values - width/2, accuracies, width, label='Accuracy')\n",
    "        ax1.bar(x_values + width/2, kappas, width, label=\"Cohen's Kappa\")\n",
    "        ax1.set_ylabel(\"Percentage\", fontsize=12)\n",
    "        ax1.set_title(\"Per-Sample Performance Metrics\", fontsize=14)\n",
    "        ax1.set_xticks(x_values)\n",
    "        ax1.set_xticklabels([s[-4:] for s in sample_names], rotation=45)\n",
    "        ax1.legend()\n",
    "        ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "        # Panel 2: Aggregated Confusion Matrix\n",
    "        ax2 = fig.add_subplot(gs[0, 1])\n",
    "        agg_cm = sum([m[\"confusion_matrix\"] for m in self.metrics_dict.values()])\n",
    "        sns.heatmap(agg_cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                    xticklabels=STAGE_NAMES, yticklabels=STAGE_NAMES, ax=ax2)\n",
    "        ax2.set_title(\"Aggregated Confusion Matrix\", fontsize=14)\n",
    "        ax2.set_xlabel(\"Predicted Stage\", fontsize=12)\n",
    "        ax2.set_ylabel(\"True Stage\", fontsize=12)\n",
    "\n",
    "        # Panel 3: Classification Report (as text)\n",
    "        ax3 = fig.add_subplot(gs[1, :])\n",
    "        ax3.axis('off')\n",
    "        overall_report = classification_report(self.overall_true, self.overall_pred,\n",
    "                                            labels=STAGE_LABELS,\n",
    "                                            target_names=STAGE_NAMES,\n",
    "                                            zero_division=0)\n",
    "        ax3.text(0.1, 0.1, f\"Overall Classification Report:\\n\\n{overall_report}\",\n",
    "                 fontfamily='monospace', fontsize=10)\n",
    "\n",
    "        # Adjust layout and save\n",
    "        plt.suptitle(f\"Sleep Staging Analysis Summary - {CURRENT_DATE}\", fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the combined figure\n",
    "        plt.savefig(os.path.join(output_dir, \"combined_analysis.png\"), \n",
    "                    bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # Also save individual hypnograms\n",
    "        for sample_name, metrics in self.metrics_dict.items():\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            time_axis = np.arange(len(metrics[\"true_stages\"])) * 30 / 3600  # Convert to hours\n",
    "            \n",
    "            plt.plot(time_axis, metrics[\"true_stages\"], label=\"True\", alpha=0.7)\n",
    "            plt.plot(time_axis, metrics[\"pred_stages\"], label=\"Predicted\", alpha=0.7)\n",
    "            \n",
    "            plt.title(f\"Hypnogram Comparison - {sample_name}\")\n",
    "            plt.xlabel(\"Time (hours)\")\n",
    "            plt.ylabel(\"Sleep Stage\")\n",
    "            plt.yticks(range(len(STAGE_NAMES)), STAGE_NAMES)\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            plt.savefig(os.path.join(output_dir, f\"hypnogram_{sample_name}.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        logger.info(f\"Plots saved to {output_dir}\")\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate a comprehensive report.\"\"\"\n",
    "        report_path = f\"sleep_analysis_report_{CURRENT_DATE.split()[0]}.txt\"\n",
    "        \n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(f\"Sleep Analysis Report\\n\")\n",
    "            f.write(f\"Generated by: {CURRENT_USER}\\n\")\n",
    "            f.write(f\"Date: {CURRENT_DATE}\\n\")\n",
    "            f.write(\"=\"*50 + \"\\n\\n\")\n",
    "            \n",
    "            # Overall metrics\n",
    "            overall_acc = accuracy_score(self.overall_true, self.overall_pred) * 100\n",
    "            overall_kappa = cohen_kappa_score(self.overall_true, self.overall_pred)\n",
    "            \n",
    "            f.write(f\"Overall Metrics:\\n\")\n",
    "            f.write(f\"Accuracy: {overall_acc:.2f}%\\n\")\n",
    "            f.write(f\"Cohen's Kappa: {overall_kappa:.2f}\\n\\n\")\n",
    "            \n",
    "            # Per-sample metrics\n",
    "            f.write(\"Per-sample Metrics:\\n\")\n",
    "            for sample_name, metrics in self.metrics_dict.items():\n",
    "                f.write(f\"\\n{sample_name}:\\n\")\n",
    "                f.write(f\"Accuracy: {metrics['accuracy']:.2f}%\\n\")\n",
    "                f.write(f\"Cohen's Kappa: {metrics['cohen_kappa']:.2f}\\n\")\n",
    "                f.write(\"\\nClassification Report:\\n\")\n",
    "                f.write(metrics['classification_report'])\n",
    "                f.write(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "        logger.info(f\"Report generated: {report_path}\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # Initialize analysis\n",
    "        dataset_dir = \"dataset/\"\n",
    "        analysis = SleepAnalysis(dataset_dir)\n",
    "        \n",
    "        # Process dataset\n",
    "        logger.info(\"Starting dataset processing\")\n",
    "        analysis.process_dataset()\n",
    "        \n",
    "        # Generate results\n",
    "        logger.info(\"Generating plots and reports\")\n",
    "        analysis.plot_results()\n",
    "        analysis.generate_report()\n",
    "        \n",
    "        logger.info(\"Analysis completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Analysis failed: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
