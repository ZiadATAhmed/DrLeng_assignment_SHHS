{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading EDF files: 100%|██████████| 50/50 [00:03<00:00, 16.22it/s]\n",
      "Extracting Apnea Events: 100%|██████████| 50/50 [00:00<00:00, 257.11it/s]\n",
      "Extracting REM Events: 100%|██████████| 50/50 [00:00<00:00, 301.13it/s]\n",
      "Fitting Models:  75%|███████▌  | 3/4 [00:02<00:00,  1.20group/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal threshold for pnni_20: 0.46\n",
      "Optimal threshold for pnni_20: 0.46\n",
      "Optimal threshold for pnni_20: 0.46\n",
      "Optimal threshold for hf: -0.19\n",
      "Optimal threshold for hf: -0.19\n",
      "Optimal threshold for hf: -0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Models: 100%|██████████| 4/4 [00:04<00:00,  1.10s/group]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyedflib\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "from hrvanalysis import get_time_domain_features, get_frequency_domain_features, get_poincare_plot_features\n",
    "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Disable warnings and suppress output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# ----------------------- Data Processing Functions -----------------------\n",
    "\n",
    "def load_edf_file(file_path: str):\n",
    "    \"\"\"Load an EDF file and return the first signal (assumed to be ECG).\"\"\"\n",
    "    try:\n",
    "        with pyedflib.EdfReader(file_path) as edf:\n",
    "            ecg_signal = edf.readSignal(0)\n",
    "        return ecg_signal\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def filter_ecg_signal(ecg_signal: np.ndarray, lowcut: float = 0.5, highcut: float = 50.0,\n",
    "                      fs: float = 1000.0, order: int = 1) -> np.ndarray:\n",
    "    \"\"\"Bandpass filter the ECG signal.\"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, ecg_signal)\n",
    "\n",
    "def detect_r_peaks(ecg_signal: np.ndarray, distance: int = 300) -> np.ndarray:\n",
    "    \"\"\"Detect R-peaks in the given ECG signal.\"\"\"\n",
    "    r_peaks, _ = find_peaks(ecg_signal, distance=distance)\n",
    "    return r_peaks\n",
    "\n",
    "def compute_hrv_metrics(r_peaks: np.ndarray, fs: float = 1000.0) -> dict:\n",
    "    \"\"\"Compute HRV metrics from the R-peaks.\"\"\"\n",
    "    rr_intervals = np.diff(r_peaks) / fs * 1000.0  # in milliseconds\n",
    "    time_domain_features = get_time_domain_features(rr_intervals)\n",
    "    frequency_domain_features = get_frequency_domain_features(rr_intervals)\n",
    "    poincare_features = get_poincare_plot_features(rr_intervals)\n",
    "    return {**time_domain_features, **frequency_domain_features, **poincare_features}\n",
    "\n",
    "def extract_apnea_events(xml_path: str):\n",
    "    \"\"\"Extract apnea events from an XML file.\"\"\"\n",
    "    events = []\n",
    "    try:\n",
    "        import xml.etree.ElementTree as ET\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        for event in root.findall('.//ScoredEvent'):\n",
    "            event_concept = event.find('EventConcept')\n",
    "            if event_concept is not None and 'apnea' in event_concept.text.lower():\n",
    "                start = event.find('Start')\n",
    "                duration = event.find('Duration')\n",
    "                if start is not None and duration is not None:\n",
    "                    start_time = float(start.text)\n",
    "                    duration_time = float(duration.text)\n",
    "                    event_type = 'unknown'\n",
    "                    concept_text = event_concept.text.lower()\n",
    "                    if 'obstructive' in concept_text:\n",
    "                        event_type = 'obstructive'\n",
    "                    elif 'central' in concept_text:\n",
    "                        event_type = 'central'\n",
    "                    elif 'mixed' in concept_text:\n",
    "                        event_type = 'mixed'\n",
    "                    events.append((start_time, duration_time, event_type))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return events\n",
    "\n",
    "def extract_rem_events(xml_path: str):\n",
    "    \"\"\"Extract REM events from an XML file.\"\"\"\n",
    "    events = []\n",
    "    try:\n",
    "        import xml.etree.ElementTree as ET\n",
    "        tree = ET.parse(xml_path)\n",
    "        root = tree.getroot()\n",
    "        for event in root.findall('.//ScoredEvent'):\n",
    "            event_concept = event.find('EventConcept')\n",
    "            if event_concept is not None and 'rem' in event_concept.text.lower():\n",
    "                start = event.find('Start')\n",
    "                duration = event.find('Duration')\n",
    "                if start is not None and duration is not None:\n",
    "                    start_time = float(start.text)\n",
    "                    duration_time = float(duration.text)\n",
    "                    events.append((start_time, duration_time))\n",
    "    except Exception:\n",
    "        pass\n",
    "    return events\n",
    "\n",
    "# ----------------------- ROC-Threshold Helper Functions -----------------------\n",
    "\n",
    "def get_optimal_threshold(data: pd.DataFrame, variable: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute the optimal threshold for a given variable using ROC analysis.\n",
    "    The optimal threshold maximizes the Youden index (tpr - fpr)\n",
    "    with respect to the binary outcome 'vital'.\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(data['vital'], data[variable])\n",
    "    youden_index = tpr - fpr\n",
    "    optimal_idx = np.argmax(youden_index)\n",
    "    return thresholds[optimal_idx]\n",
    "\n",
    "def create_group_column(data: pd.DataFrame, variable: str, threshold: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a group column in the DataFrame based on the given variable and threshold.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    data['group'] = np.where(data[variable] >= threshold, 'High', 'Low')\n",
    "    return data\n",
    "\n",
    "# ----------------------- Plotting Functions for Reports -----------------------\n",
    "\n",
    "def plot_forest(model: CoxPHFitter, title: str):\n",
    "    \"\"\"Generate a forest plot similar to R's forestplot.\"\"\"\n",
    "    summary = model.summary.copy().round(2)\n",
    "    summary_sorted = summary.sort_values(by='exp(coef)')\n",
    "    num_features = summary_sorted.shape[0]\n",
    "    \n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(8, num_features * 0.4 + 2), dpi=300)\n",
    "    \n",
    "    y_positions = range(num_features)\n",
    "    hr_vals = summary_sorted['exp(coef)'].values\n",
    "    lower_vals = summary_sorted['exp(coef) lower 95%'].values\n",
    "    upper_vals = summary_sorted['exp(coef) upper 95%'].values\n",
    "    errors = [hr_vals - lower_vals, upper_vals - hr_vals]\n",
    "    \n",
    "    ax.errorbar(hr_vals, y_positions, xerr=errors, fmt='s', color='black', \n",
    "                ecolor='green', elinewidth=1.5, capsize=3)\n",
    "    ax.axvline(x=1, color='red', linestyle='--', linewidth=1)\n",
    "    ax.set_yticks(y_positions)\n",
    "    ax.set_yticklabels(summary_sorted.index, fontsize=7)\n",
    "    ax.set_xlabel('Hazard Ratio (log scale)', fontsize=8)\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.set_xscale('log')\n",
    "    plt.subplots_adjust(left=0.3, right=0.95, top=0.92, bottom=0.1)\n",
    "    return fig\n",
    "\n",
    "def plot_model_summary(model: CoxPHFitter, title: str):\n",
    "    \"\"\"Generate a table of the model summary with numbers rounded to two decimals.\"\"\"\n",
    "    summary = model.summary.copy().round(2)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, summary.shape[0] * 0.25 + 1.5), dpi=300)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table = ax.table(cellText=summary.values,\n",
    "                     colLabels=summary.columns,\n",
    "                     rowLabels=summary.index,\n",
    "                     loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(6)\n",
    "    ax.set_title(f\"{title} - Model Summary\", fontweight=\"bold\", fontsize=10)\n",
    "    plt.subplots_adjust(left=0.2, right=0.95, top=0.9, bottom=0.1)\n",
    "    return fig\n",
    "\n",
    "def plot_performance_metrics(model: CoxPHFitter, c_index: float, title: str):\n",
    "    \"\"\"Generate a table of performance metrics (C-index, Log-likelihood, AIC).\"\"\"\n",
    "    try:\n",
    "        log_likelihood = model.log_likelihood_\n",
    "    except Exception:\n",
    "        log_likelihood = np.nan\n",
    "    try:\n",
    "        aic = model.AIC_partial_\n",
    "    except Exception:\n",
    "        aic = np.nan\n",
    "    \n",
    "    metrics_data = {\n",
    "        \"Metric\": [\"C-index\", \"Log-likelihood\", \"AIC\"],\n",
    "        \"Value\": [round(c_index, 2), round(log_likelihood, 2), round(aic, 2)]\n",
    "    }\n",
    "    df_metrics = pd.DataFrame(metrics_data)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(4, 1.2), dpi=300)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    table = ax.table(cellText=df_metrics.values, colLabels=df_metrics.columns, loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(8)\n",
    "    ax.set_title(f\"{title} - Performance Metrics\", fontweight=\"bold\", fontsize=10)\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, top=0.9, bottom=0)\n",
    "    return fig\n",
    "\n",
    "def plot_km_scatter(variable: str, data: pd.DataFrame, title: str):\n",
    "    \"\"\"\n",
    "    Generate Kaplan-Meier plots using a ROC-derived threshold.\n",
    "    The ROC analysis determines the optimal cutoff for the variable,\n",
    "    splitting the data into \"High\" and \"Low\" groups.\n",
    "    \"\"\"\n",
    "    optimal_threshold = get_optimal_threshold(data, variable)\n",
    "    print(f\"Optimal threshold for {variable}: {optimal_threshold:.2f}\")\n",
    "    \n",
    "    group_data = create_group_column(data, variable, optimal_threshold)\n",
    "    group_high = group_data[group_data['group'] == 'High']\n",
    "    group_low = group_data[group_data['group'] == 'Low']\n",
    "    \n",
    "    kmf = KaplanMeierFitter()\n",
    "    fig, ax = plt.subplots(figsize=(6, 5), dpi=300)\n",
    "    \n",
    "    # Plot KM curve for high values\n",
    "    kmf.fit(group_high['censdate'], event_observed=group_high['vital'], label=f\"{variable} High\")\n",
    "    kmf.plot(ax=ax, marker='o', ci_show=True, linewidth=1.2)\n",
    "    \n",
    "    # Plot KM curve for low values\n",
    "    kmf.fit(group_low['censdate'], event_observed=group_low['vital'], label=f\"{variable} Low\")\n",
    "    kmf.plot(ax=ax, marker='o', ci_show=True, linewidth=1.2)\n",
    "    \n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.set_xlabel(\"Time\", fontsize=9)\n",
    "    ax.set_ylabel(\"Survival Probability\", fontsize=9)\n",
    "    plt.subplots_adjust(left=0.15, right=0.95, top=0.9, bottom=0.15)\n",
    "    return fig\n",
    "\n",
    "def plot_density_event_status_with_threshold(variable: str, data: pd.DataFrame, title: str):\n",
    "    \"\"\"\n",
    "    Generate a density plot for the given variable using a ROC-derived optimal threshold.\n",
    "    The data are split into \"High\" and \"Low\" groups, and vertical lines are drawn at the threshold and each group's median.\n",
    "    \"\"\"\n",
    "    optimal_threshold = get_optimal_threshold(data, variable)\n",
    "    print(f\"Optimal threshold for {variable}: {optimal_threshold:.2f}\")\n",
    "    \n",
    "    # Create groups based on the threshold\n",
    "    data = create_group_column(data, variable, optimal_threshold)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 5), dpi=300)\n",
    "    \n",
    "    # Data for each group\n",
    "    subset_high = data[data['group'] == 'High']\n",
    "    subset_low = data[data['group'] == 'Low']\n",
    "    \n",
    "    # Plot density curves for each group\n",
    "    sns.kdeplot(x=subset_high[variable], label=\"High Group\", fill=True, common_norm=False, alpha=0.5, ax=ax)\n",
    "    sns.kdeplot(x=subset_low[variable], label=\"Low Group\", fill=True, common_norm=False, alpha=0.5, ax=ax)\n",
    "    \n",
    "    # Draw vertical line at the optimal threshold\n",
    "    ax.axvline(optimal_threshold, linestyle='--', color='red', linewidth=1, label=f\"Threshold = {optimal_threshold:.2f}\")\n",
    "    \n",
    "    # Calculate and plot medians for each group\n",
    "    high_median = subset_high[variable].median()\n",
    "    low_median = subset_low[variable].median()\n",
    "    ax.axvline(high_median, linestyle='--', color='blue', linewidth=1, label=f\"High Median = {high_median:.2f}\")\n",
    "    ax.axvline(low_median, linestyle='--', color='green', linewidth=1, label=f\"Low Median = {low_median:.2f}\")\n",
    "    \n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.set_xlabel(f\"{variable} Value\", fontsize=9)\n",
    "    ax.set_ylabel(\"Density\", fontsize=9)\n",
    "    ax.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_violin_event_status_with_threshold(variable: str, data: pd.DataFrame, title: str):\n",
    "    \"\"\"\n",
    "    Generate a violin plot for the given variable using a ROC-derived optimal threshold.\n",
    "    The data is grouped into \"High\" and \"Low\" based on the optimal threshold.\n",
    "    Median values for each group are overlaid on the plot.\n",
    "    \"\"\"\n",
    "    optimal_threshold = get_optimal_threshold(data, variable)\n",
    "    print(f\"Optimal threshold for {variable}: {optimal_threshold:.2f}\")\n",
    "    \n",
    "    # Create groups based on the threshold\n",
    "    data = create_group_column(data, variable, optimal_threshold)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 5), dpi=300)\n",
    "    \n",
    "    sns.violinplot(x=\"group\", y=variable, data=data, palette=\"Set2\", ax=ax, inner=\"quartile\")\n",
    "    \n",
    "    # Calculate medians for each group and overlay scatter markers\n",
    "    group_medians = data.groupby(\"group\")[variable].median().reset_index()\n",
    "    for idx, row in group_medians.iterrows():\n",
    "        # Determine the x-axis position for each group in the violin plot\n",
    "        # Adjust the x positions if needed depending on plot order\n",
    "        x_pos = 0 if row[\"group\"] == \"High\" else 1\n",
    "        ax.scatter(x_pos, row[variable], color=\"black\", zorder=10, s=50, label=f\"{row['group']} Median = {row[variable]:.2f}\")\n",
    "    \n",
    "    # Avoid duplicate labels in legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    unique = dict(zip(labels, handles))\n",
    "    ax.legend(unique.values(), unique.keys(), fontsize=8)\n",
    "    \n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.set_xlabel(\"Group (based on optimal threshold)\", fontsize=9)\n",
    "    ax.set_ylabel(f\"{variable} Value\", fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def generate_model_report(model: CoxPHFitter, group_name: str, c_index: float, subset: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Generate a multipage PDF report for the given model group.\n",
    "    The report includes:\n",
    "      - A forest plot, model summary table, and performance metrics.\n",
    "      - Kaplan-Meier plots using a ROC-derived threshold.\n",
    "      - Density and violin plots for each significant variable using the optimal threshold, including lines for group medians.\n",
    "    \"\"\"\n",
    "    report_filename = f\"model_report_{group_name.lower().replace(' ', '_')}.pdf\"\n",
    "    with PdfPages(report_filename) as pdf:\n",
    "        # Page 1: Forest Plot\n",
    "        forest_fig = plot_forest(model, f\"Forest Plot: {group_name}\")\n",
    "        pdf.savefig(forest_fig, bbox_inches=\"tight\")\n",
    "        plt.close(forest_fig)\n",
    "        \n",
    "        # Page 2: Model Summary\n",
    "        summary_fig = plot_model_summary(model, group_name)\n",
    "        pdf.savefig(summary_fig, bbox_inches=\"tight\")\n",
    "        plt.close(summary_fig)\n",
    "        \n",
    "        # Page 3: Performance Metrics\n",
    "        performance_fig = plot_performance_metrics(model, c_index, group_name)\n",
    "        pdf.savefig(performance_fig, bbox_inches=\"tight\")\n",
    "        plt.close(performance_fig)\n",
    "        \n",
    "        # For each significant variable (p < 0.05), plot KM, density, and violin plots.\n",
    "        significant_vars = model.summary[model.summary['p'] < 0.05].index.tolist()\n",
    "        for var in significant_vars:\n",
    "            if var in subset.columns:\n",
    "                km_fig = plot_km_scatter(var, subset, f\"Kaplan-Meier Plot for {var} ({group_name})\")\n",
    "                pdf.savefig(km_fig, bbox_inches=\"tight\")\n",
    "                plt.close(km_fig)\n",
    "                \n",
    "                density_fig = plot_density_event_status_with_threshold(var, subset, f\"Density Plot for {var} by Vital ({group_name})\")\n",
    "                pdf.savefig(density_fig, bbox_inches=\"tight\")\n",
    "                plt.close(density_fig)\n",
    "                \n",
    "                violin_fig = plot_violin_event_status_with_threshold(var, subset, f\"Violin Plot for {var} by Vital ({group_name})\")\n",
    "                pdf.savefig(violin_fig, bbox_inches=\"tight\")\n",
    "                plt.close(violin_fig)\n",
    "\n",
    "# ----------------------- Main Processing Pipeline -----------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_folder = 'dataset'\n",
    "    edf_files = [os.path.join(dataset_folder, f) for f in os.listdir(dataset_folder) if f.endswith('.edf')]\n",
    "    xml_files = [os.path.join(dataset_folder, f) for f in os.listdir(dataset_folder) if f.endswith('.xml')]\n",
    "\n",
    "    # Process EDF files with TQDM progress bar\n",
    "    ecg_signals = []\n",
    "    for file in tqdm(edf_files, desc=\"Loading EDF files\"):\n",
    "        signal = load_edf_file(file)\n",
    "        if signal is not None:\n",
    "            ecg_signals.append(signal)\n",
    "    filtered_signals = [filter_ecg_signal(signal) for signal in ecg_signals]\n",
    "    r_peaks_list = [detect_r_peaks(signal) for signal in filtered_signals]\n",
    "    hrv_metrics_list = [compute_hrv_metrics(r_peaks) for r_peaks in r_peaks_list]\n",
    "    hrv_df = pd.DataFrame(hrv_metrics_list)\n",
    "\n",
    "    # Process XML files for apnea and REM events with TQDM progress\n",
    "    apnea_events_list = [extract_apnea_events(file) for file in tqdm(xml_files, desc=\"Extracting Apnea Events\")]\n",
    "    recording_duration_hours = 8\n",
    "    ahi_list = [len(events) / recording_duration_hours for events in apnea_events_list]\n",
    "    hrv_df['AHI'] = ahi_list\n",
    "    hrv_df['apnea_status'] = hrv_df['AHI'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "    rem_events_list = [extract_rem_events(file) for file in tqdm(xml_files, desc=\"Extracting REM Events\")]\n",
    "    recording_duration_seconds = 8 * 3600\n",
    "    rem_total_durations = [sum(event[1] for event in events) for events in rem_events_list]\n",
    "    rem_fraction = [duration / recording_duration_seconds for duration in rem_total_durations]\n",
    "    hrv_df['rem_fraction'] = rem_fraction\n",
    "    hrv_df['rem_status'] = hrv_df['rem_fraction'].apply(lambda x: 'REM' if x >= 0.2 else 'Not REM')\n",
    "\n",
    "    # Load mortality data and combine with HRV data\n",
    "    mortality_data_path = 'outcomes.csv'\n",
    "    mortality_data = pd.read_csv(mortality_data_path)\n",
    "    combined_data = pd.concat([hrv_df.reset_index(drop=True), mortality_data.reset_index(drop=True)], axis=1)\n",
    "    combined_data_clean = combined_data.dropna().reset_index(drop=True)\n",
    "\n",
    "    non_hrv = [\"AHI\", \"apnea_status\", \"rem_fraction\", \"rem_status\", \"censdate\", \"vital\"]\n",
    "    hrv_metric_columns = [col for col in hrv_df.columns if col not in non_hrv]\n",
    "    scaler = StandardScaler()\n",
    "    data_for_scaling = combined_data_clean[hrv_metric_columns]\n",
    "    scaled_data = scaler.fit_transform(data_for_scaling)\n",
    "    scaled_hrv_df = pd.DataFrame(scaled_data, columns=hrv_metric_columns)\n",
    "\n",
    "    combined_data_clean_scaled = combined_data_clean.copy()\n",
    "    for col in hrv_metric_columns:\n",
    "        combined_data_clean_scaled[col] = scaled_hrv_df[col]\n",
    "\n",
    "    survival_columns = ['censdate', 'vital']\n",
    "    model_columns = hrv_metric_columns + survival_columns\n",
    "\n",
    "    # Define data subsets for four groups based on apnea and REM status\n",
    "    subset_apnea_rem = combined_data_clean_scaled[\n",
    "        (combined_data_clean_scaled['apnea_status'] == 1) & (combined_data_clean_scaled['rem_status'] == 'REM')]\n",
    "    subset_apnea_notrem = combined_data_clean_scaled[\n",
    "        (combined_data_clean_scaled['apnea_status'] == 1) & (combined_data_clean_scaled['rem_status'] == 'Not REM')]\n",
    "    subset_noapnea_rem = combined_data_clean_scaled[\n",
    "        (combined_data_clean_scaled['apnea_status'] == 0) & (combined_data_clean_scaled['rem_status'] == 'REM')]\n",
    "    subset_noapnea_notrem = combined_data_clean_scaled[\n",
    "        (combined_data_clean_scaled['apnea_status'] == 0) & (combined_data_clean_scaled['rem_status'] == 'Not REM')]\n",
    "\n",
    "    models = [\n",
    "        (\"Apnea & REM\", subset_apnea_rem),\n",
    "        (\"Apnea & Not REM\", subset_apnea_notrem),\n",
    "        (\"No Apnea & REM\", subset_noapnea_rem),\n",
    "        (\"No Apnea & Not REM\", subset_noapnea_notrem)\n",
    "    ]\n",
    "    \n",
    "    for group_name, subset in tqdm(models, desc=\"Fitting Models\", unit=\"group\"):\n",
    "        if subset.empty:\n",
    "            continue\n",
    "        try:\n",
    "            cox_model = CoxPHFitter(penalizer=0.1)\n",
    "            cox_model.fit(subset[model_columns], duration_col='censdate', event_col='vital', show_progress=False)\n",
    "            \n",
    "            c_index = concordance_index(\n",
    "                subset['censdate'],\n",
    "                -cox_model.predict_partial_hazard(subset),\n",
    "                subset['vital']\n",
    "            )\n",
    "            \n",
    "            generate_model_report(cox_model, group_name, c_index, subset)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    hrv_df.drop(columns=[\"rem_status\"]).to_csv(\"hrv_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
